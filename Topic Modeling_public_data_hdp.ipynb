{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6deebf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import numpy.random as nprand\n",
    "import math as math\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c244962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sao107\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run in python console\n",
    "import nltk; nltk.download('stopwords')\n",
    "\n",
    "# Run in terminal or command prompt\n",
    "#!python3 -m spacy download en\n",
    "#!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0648524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca719164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c33bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "#import pyLDAvis.gensim  # don't skip this\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0922bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "#stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ba7b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postid</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>words</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40471439</td>\n",
       "      <td>blockchain diffie-hellman encryption javascript</td>\n",
       "      <td>js diffi hellman ssl blockchain auth</td>\n",
       "      <td>tri figur secur qualiti ssl mimick without nee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>encrypt|scripting|diffie hellman|ssl|security|...</td>\n",
       "      <td>2016-11-07 17:52:22.793 UTC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32771909</td>\n",
       "      <td>cryptography jar jarsigner java smartcard</td>\n",
       "      <td>sign jar smartcard</td>\n",
       "      <td>use pkcs11 smartcard work jarsign sign jar fil...</td>\n",
       "      <td>ad -sigalg algortihm avail [sha256withrsa case...</td>\n",
       "      <td>crypt|signing|certificate|validate|private key...</td>\n",
       "      <td>2015-09-24 22:23:45.947 UTC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15574818</td>\n",
       "      <td>java jespa ntlm servlets spring-security</td>\n",
       "      <td>cannot creat session respons commit ie7 ie8</td>\n",
       "      <td>work applic allow user login use ntlm form log...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>security|login|credential|password|validate|au...</td>\n",
       "      <td>2013-03-22 16:04:18.12 UTC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19042957</td>\n",
       "      <td>asp.net c# security</td>\n",
       "      <td>strong name assembl</td>\n",
       "      <td>thought learn strong name creat one exampl cac...</td>\n",
       "      <td>refer strong-nam assembl normal assembl includ...</td>\n",
       "      <td>security|signing|public key|signature|private key</td>\n",
       "      <td>2013-09-27 04:51:44.143 UTC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59694966</td>\n",
       "      <td>ssh digital-ocean cyberduck</td>\n",
       "      <td>eof read packet</td>\n",
       "      <td>connect via sftp digitalocean vps username/pas...</td>\n",
       "      <td>need updat password termin window *open digit ...</td>\n",
       "      <td>sftp|username|password|authentication|login</td>\n",
       "      <td>11/1/2020 13:43</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     postid                                             tags  \\\n",
       "0  40471439  blockchain diffie-hellman encryption javascript   \n",
       "1  32771909        cryptography jar jarsigner java smartcard   \n",
       "2  15574818         java jespa ntlm servlets spring-security   \n",
       "3  19042957                              asp.net c# security   \n",
       "4  59694966                      ssh digital-ocean cyberduck   \n",
       "\n",
       "                                         title  \\\n",
       "0         js diffi hellman ssl blockchain auth   \n",
       "1                           sign jar smartcard   \n",
       "2  cannot creat session respons commit ie7 ie8   \n",
       "3                          strong name assembl   \n",
       "4                              eof read packet   \n",
       "\n",
       "                                            question  \\\n",
       "0  tri figur secur qualiti ssl mimick without nee...   \n",
       "1  use pkcs11 smartcard work jarsign sign jar fil...   \n",
       "2  work applic allow user login use ntlm form log...   \n",
       "3  thought learn strong name creat one exampl cac...   \n",
       "4  connect via sftp digitalocean vps username/pas...   \n",
       "\n",
       "                                             answers  \\\n",
       "0                                                NaN   \n",
       "1  ad -sigalg algortihm avail [sha256withrsa case...   \n",
       "2                                                NaN   \n",
       "3  refer strong-nam assembl normal assembl includ...   \n",
       "4  need updat password termin window *open digit ...   \n",
       "\n",
       "                                               words  \\\n",
       "0  encrypt|scripting|diffie hellman|ssl|security|...   \n",
       "1  crypt|signing|certificate|validate|private key...   \n",
       "2  security|login|credential|password|validate|au...   \n",
       "3  security|signing|public key|signature|private key   \n",
       "4        sftp|username|password|authentication|login   \n",
       "\n",
       "                 creation_date Related  \n",
       "0  2016-11-07 17:52:22.793 UTC     Yes  \n",
       "1  2015-09-24 22:23:45.947 UTC     Yes  \n",
       "2   2013-03-22 16:04:18.12 UTC     Yes  \n",
       "3  2013-09-27 04:51:44.143 UTC     Yes  \n",
       "4              11/1/2020 13:43     Yes  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read iris.csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('security.csv',encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d847680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encrypt|scripting|diffie '\n",
      " 'hellman|ssl|security|authentication|certificate|authorise|public key',\n",
      " 'crypt|signing|certificate|validate|private key|dsa|rsa|availability',\n",
      " 'security|login|credential|password|validate|authentication',\n",
      " 'security|signing|public key|signature|private key']\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df.words.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "#data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "#data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "#data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1103bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "print(len(data_words))\n",
    "\n",
    "\n",
    "#print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "291f7042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['security', 'openid', 'oauth', 'login', 'authorise', 'authentication', 'validate', 'hack']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[100]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e42620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a021a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "754a7fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['encrypt', 'scripting', 'security', 'authentication', 'certificate', 'authorise', 'public', 'key'], ['sign', 'certificate', 'validate', 'private', 'key'], ['security', 'login', 'credential', 'password', 'validate', 'authentication'], ['security', 'sign', 'public', 'key', 'signature', 'private', 'key'], ['sftp', 'username', 'password', 'authentication', 'login'], ['encrypt'], ['delegation', 'transport', 'security', 'privilege', 'authentication'], ['security', 'encrypt'], ['security', 'transport', 'certificate', 'trust', 'validate', 'insecure', 'bypass'], ['certificate', 'signature', 'hash', 'encode', 'validate']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp = spacy.load(\"en_core_web_sm\",disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ace47122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e1caff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('authentication', 1),\n",
       "  ('authorise', 1),\n",
       "  ('certificate', 1),\n",
       "  ('encrypt', 1),\n",
       "  ('key', 1),\n",
       "  ('public', 1),\n",
       "  ('scripting', 1),\n",
       "  ('security', 1)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19d72fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build hdp model\n",
    "hdp_model = gensim.models.HdpModel(corpus, \n",
    "                                   id2word, \n",
    "                                   chunksize=10,\n",
    "                                   random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fb34225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.041*sign + 0.038*virus + 0.034*penetration + 0.033*hmac + 0.028*tls + '\n",
      "  '0.025*adversarial + 0.024*cookie + 0.024*pbkdf + 0.022*spam + 0.021*spnego'),\n",
      " (1,\n",
      "  '0.049*access + 0.037*spoof + 0.033*sign + 0.029*signature + 0.029*firewall '\n",
      "  '+ 0.028*password + 0.027*sanitise + 0.026*tls + 0.022*rbac + 0.022*tamper'),\n",
      " (2,\n",
      "  '0.040*tunnel + 0.035*mitm + 0.033*test + 0.032*table + 0.031*crypt + '\n",
      "  '0.028*key + 0.027*burp + 0.026*trust + 0.024*validate + 0.024*protect'),\n",
      " (3,\n",
      "  '0.041*sandbox + 0.034*crc + 0.031*access + 0.026*penetration + 0.025*snif + '\n",
      "  '0.025*login + 0.025*intruder + 0.024*sign + 0.022*cipher + 0.021*control'),\n",
      " (4,\n",
      "  '0.058*injection + 0.040*leak + 0.032*credential + 0.031*salt + '\n",
      "  '0.028*validate + 0.028*thread + 0.025*crypt + 0.024*authentication + '\n",
      "  '0.022*forge + 0.021*bypass'),\n",
      " (5,\n",
      "  '0.038*sanitise + 0.038*delegation + 0.034*sensitive + 0.031*private + '\n",
      "  '0.030*danger + 0.026*certificate + 0.026*audit + 0.022*access + '\n",
      "  '0.022*encrypt + 0.020*encode'),\n",
      " (6,\n",
      "  '0.041*cbc + 0.039*scripting + 0.028*sanitise + 0.026*encrypt + 0.026*md + '\n",
      "  '0.025*pbkdf + 0.024*cross + 0.022*encode + 0.020*snif + 0.019*public'),\n",
      " (7,\n",
      "  '0.053*security + 0.037*tunnelling + 0.029*exploit + 0.027*crypt + '\n",
      "  '0.026*malicious + 0.024*password + 0.022*authentication + 0.022*username + '\n",
      "  '0.021*hsm + 0.020*sftp'),\n",
      " (8,\n",
      "  '0.042*honeypot + 0.039*availability + 0.033*sftp + 0.028*decode + '\n",
      "  '0.026*spoof + 0.026*hmac + 0.026*exploit + 0.024*theft + 0.023*nonce + '\n",
      "  '0.021*script'),\n",
      " (9,\n",
      "  '0.044*sql + 0.034*theft + 0.031*eavesdropping + 0.031*md + 0.029*intruder + '\n",
      "  '0.025*csrf + 0.022*trust + 0.021*ssh + 0.021*danger + 0.021*mitm'),\n",
      " (10,\n",
      "  '0.048*threat + 0.045*availability + 0.029*account + 0.028*confidential + '\n",
      "  '0.028*asset + 0.027*snif + 0.026*openid + 0.026*hash + 0.024*tunnel + '\n",
      "  '0.023*cross'),\n",
      " (11,\n",
      "  '0.044*site + 0.036*confidential + 0.032*sensitive + 0.031*mitm + '\n",
      "  '0.030*validate + 0.028*fingerprint + 0.026*inject + 0.026*sftp + 0.020*hack '\n",
      "  '+ 0.020*hsm'),\n",
      " (12,\n",
      "  '0.048*firewall + 0.039*captcha + 0.033*gnupg + 0.032*crypt + 0.030*rsa + '\n",
      "  '0.027*cbc + 0.026*privilege + 0.025*public + 0.024*vector + 0.024*inject'),\n",
      " (13,\n",
      "  '0.038*captcha + 0.034*forge + 0.028*md + 0.028*adversarial + 0.028*crc + '\n",
      "  '0.027*openssh + 0.027*delegation + 0.027*attack + 0.025*validate + '\n",
      "  '0.024*access'),\n",
      " (14,\n",
      "  '0.038*sanitise + 0.034*sensitive + 0.032*disclosure + 0.032*password + '\n",
      "  '0.030*danger + 0.030*rbac + 0.029*openid + 0.025*authentication + '\n",
      "  '0.022*encrypt + 0.020*name'),\n",
      " (15,\n",
      "  '0.029*audit + 0.028*script + 0.028*name + 0.027*cbc + 0.026*inject + '\n",
      "  '0.026*key + 0.023*mitm + 0.023*access + 0.023*authorise + 0.023*backdoor'),\n",
      " (16,\n",
      "  '0.036*day + 0.034*hash + 0.031*tunnel + 0.031*information + 0.025*captcha + '\n",
      "  '0.025*authentication + 0.025*theft + 0.024*ssh + 0.024*md + 0.022*cookie'),\n",
      " (17,\n",
      "  '0.044*fingerprint + 0.037*bypass + 0.029*user + 0.028*rbac + '\n",
      "  '0.025*credential + 0.024*table + 0.023*snif + 0.023*tls + 0.022*rainbow + '\n",
      "  '0.021*burp'),\n",
      " (18,\n",
      "  '0.040*penetration + 0.033*gnupg + 0.032*asset + 0.023*vulnerability + '\n",
      "  '0.022*signing + 0.022*exploit + 0.022*spnego + 0.021*control + '\n",
      "  '0.020*username + 0.020*firewall'),\n",
      " (19,\n",
      "  '0.046*key + 0.037*disclosure + 0.027*delegation + 0.027*crypt + '\n",
      "  '0.027*hijacking + 0.026*sanitise + 0.022*sensitive + 0.020*leak + '\n",
      "  '0.020*backdoor + 0.018*authorise')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(hdp_model.print_topics())\n",
    "doc_hdp = hdp_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d59cc746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(69, 0.4901064398717601), (81, 0.4003818836660858)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdp_model[corpus[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
